# YouTube 13강/책 ch 5-3. 트리의 앙상블

## 예제 소스코드
**트리의 앙상블(Tree Ensemble)** 기법들을 체계적으로 비교 분석하는 완전한 워크플로우 제시

### 1. 데이터 준비 단계
```python
wine = pd.read_csv('https://bit.ly/wine_csv_data')
data = wine[['alcohol', 'sugar', 'pH']]
target = wine['class']
```
와인 데이터셋을 활용하여 3개의 특성(알코올, 당분, pH)으로 와인 품질을 분류하는 문제를 설정합니다.
- 이는 실제 업무에서 금융 상품의 리스크 등급을 분류하는 것과 유사한 패턴입니다.

### 2. 앙상블 기법들의 진화적 학습

**2-1. Random Forest (랜덤포레스트)**
- **핵심 원리**: 배깅(Bagging) + 특성 무작위 선택
- **작동 방식**: 여러 개의 결정트리를 독립적으로 훈련시키고 투표로 결과 결정
- **장점**: 과적합 방지, 안정적 성능
- **결과**: 훈련 정확도 99.7%, 검증 정확도 89.1%

```python
rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)
```
OOB(Out-of-Bag) 스코어를 통해 별도의 검증 세트 없이도 모델 성능을 평가할 수 있습니다.

**2-2. Extra Trees (엑스트라트리)**
- **핵심 차이점**: 최적 분할점 대신 무작위 분할점 사용
- **컴퓨팅 효율성**: Random Forest보다 빠른 훈련 속도
- **결과**: 비슷한 성능(훈련 99.7%, 검증 88.9%)

**2-3. Gradient Boosting (그레이디언트 부스팅)**
- **패러다임 전환**: 배깅에서 부스팅으로
- **순차적 학습**: 이전 모델의 오차를 다음 모델이 보완
- **하이퍼파라미터 최적화**:
  ```python
  gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2)
  ```
- **성능 향상**: 기본 설정(88.8%/87.2%) → 튜닝 후(94.6%/87.8%)

## 고급 부스팅 기법들의 특징 분석

### 3. Histogram-based Gradient Boosting
```python
hgb = HistGradientBoostingClassifier(random_state=42)
```
- **기술적 혁신**: 히스토그램 기반 분할로 메모리 효율성 향상
- **대용량 데이터 처리**: 기존 그레이디언트 부스팅의 확장성 한계 극복
- **Permutation Importance**: 특성 중요도를 더 신뢰할 수 있는 방식으로 측정

### 4. 산업 표준 라이브러리들
**XGBoost**: 
- 경진대회와 실무에서 가장 널리 사용
- `tree_method='hist'` 옵션으로 최적화

**LightGBM**:
- Microsoft 개발, 빠른 속도와 메모리 효율성
- 대규모 데이터셋에서 특히 우수한 성능

## 핵심 개념들의 상호관계

### 앙상블의 두 가지 철학
1. **병렬 처리 (Bagging)**: Random Forest, Extra Trees
   - 독립적 모델들의 평균화로 분산 감소
   - 과적합 방지에 효과적

2. **순차 처리 (Boosting)**: Gradient Boosting 계열
   - 약한 학습기들의 순차적 개선
   - 편향 감소에 효과적

### 성능 vs 해석가능성 트레이드오프
- **특성 중요도 분석**: 모든 모델에서 'sugar' 특성이 가장 중요
- **Permutation Importance**: 실제 예측 성능에 미치는 영향 측정
- **비즈니스 인사이트**: 와인 품질 예측에서 당분 함량이 핵심 요소

## 실무 적용을 위한 고려사항

### 모델 선택 가이드라인
- **안정성 우선**: Random Forest (금융권 리스크 모델에 적합)
- **성능 우선**: XGBoost/LightGBM (마케팅 예측 모델에 적합)
- **해석가능성 우선**: Histogram-based GB + Permutation Importance

### 하이퍼파라미터 최적화 전략
각 모델의 핵심 파라미터들이 성능에 미치는 영향을 체계적으로 분석하여, 실제 프로젝트에서 효율적인 튜닝 전략을 수립할 수 있습니다.

---

**심화 탐구를 위한 질문들:**

1. 금융 도메인에서 이러한 앙상블 기법들을 신용평가나 사기탐지에 적용할 때, 각각의 장단점과 규제 준수 관점에서의 고려사항은 무엇일까요?

2. 대용량 실시간 데이터 처리가 필요한 환경에서 이들 알고리즘의 추론 속도와 메모리 사용량을 최적화하는 엔지니어링 접근법은 어떻게 될까요?

3. 앙상블 모델의 예측 결과에 대한 불확실성(uncertainty)을 정량화하고, 이를 비즈니스 의사결정에 활용하는 방법론은 어떤 것들이 있을까요?
